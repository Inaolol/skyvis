# SkyVis - Aerial Object Detection System

<div align="center">

![SkyVis Logo](UML_Diagram.png)

**Real-time Object Detection and Position Estimation for Aerial Surveillance**

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8-blue.svg)](https://python.org)
[![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-orange.svg)](https://ultralytics.com)

*Teknofest AI in Transportation Competition Submission*

</div>

## ğŸ¯ Project Overview

SkyVis is a sophisticated aerial surveillance system developed for the **Teknofest AI in Transportation Competition**. The system performs real-time object detection and camera position estimation from aerial imagery, connecting to a competition evaluation server to process frames and submit predictions.

### Key Features

- ğŸš **Real-time Object Detection**: YOLO-based detection of vehicles, humans, and aircraft
- ğŸ“ **Position Estimation**: Optical flow-based camera movement tracking
- ğŸŒ **Server Integration**: Seamless connection to competition evaluation server
- âš¡ **Performance Optimized**: 3 FPS processing with efficient caching
- ğŸ¯ **Landing Zone Classification**: Automated assessment of landing suitability

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Competition   â”‚â”€â”€â”€â”€â”‚   SkyVis Core    â”‚â”€â”€â”€â”€â”‚   AI Models     â”‚
â”‚     Server      â”‚    â”‚     Pipeline     â”‚    â”‚   (YOLO+CV)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Frames  â”‚             â”‚ Process â”‚             â”‚ Detect  â”‚
    â”‚Download â”‚             â”‚ & Cache â”‚             â”‚& Track  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

| Component | Description | Modifiable |
|-----------|-------------|------------|
| `main.py` | Entry point and orchestration | âŒ |
| `src/object_detection_model.py` | YOLO inference and processing | âœ… |
| `src/connection_handler.py` | Server communication | âŒ |
| `src/position_estimator.py` | Optical flow tracking | âŒ |
| `scripts/training.ipynb` | Model training pipeline | âœ… |

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8
- NVIDIA GPU (recommended)
- Anaconda/Miniconda

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Inaolol/skyvis.git
   cd skyvis
   ```

2. **Create virtual environment**
   ```bash
   conda create -n yarisma python=3.8
   conda activate yarisma
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure credentials**
   
   Create `config/.env` with your competition credentials:
   ```env
   TEAM_NAME=your_team_name
   PASSWORD=your_password
   EVALUATION_SERVER_URL="https://competition-server-url"
   SESSION_NAME=your_session_name
   ```

5. **Run the system**
   ```bash
   python main.py
   ```

## ğŸ”§ Development Workflow

### Model Training

Use the provided Jupyter notebook for training custom YOLO models:

```bash
jupyter notebook scripts/training.ipynb
```

### Dataset Utilities

The `scripts/` directory contains useful tools:

- `folder2textYolo.py` - Generate train/validation splits
- `visualize_yolo.py` - Visualize annotations
- `Voc_2_yolo.py` - Convert VOC format to YOLO

### Model Integration

**âš ï¸ Competition Rule**: Only modify `src/object_detection_model.py`

Update the model path in the ObjectDetectionModel class:
```python
self.model = YOLO("path/to/your/best.pt")
```

## ğŸ“Š Object Classes & Detection

### Supported Objects

| Turkish Name | English | Class ID | Description |
|--------------|---------|----------|-------------|
| Tasit | Vehicle | 0 | Cars, trucks, etc. |
| Insan | Human | 1 | People detection |
| UAP | UAV | 2 | Unmanned Aerial Vehicle |
| UAI | UAI | 3 | Unmanned Aerial Infrastructure |

### Landing Status Classification

| Turkish | English | Code | Description |
|---------|---------|------|-------------|
| Inilebilir | Landable | "1" | Safe landing zone |
| Inilemez | Not Landable | "0" | Unsafe for landing |
| Inis Alani Degil | Not Landing Area | "-1" | Not a landing area |

## ğŸ›ï¸ Configuration

### Camera Calibration

The system uses pre-calibrated camera parameters from `Calibration Parameters.txt`:
- **Focal Length**: 1413.3 x 1418.8 pixels
- **Principal Point**: (950.06, 543.38)
- **Distortion**: Radial and tangential correction

### Performance Settings

- **Target FPS**: 3.0 (competition requirement)
- **Image Resize**: 50% for performance
- **YOLO Config**: `conf=0.4, imgsz=800, device=0`

## ğŸ“ Project Structure

```
skyvis/
â”œâ”€â”€ ğŸ“„ main.py                 # Entry point
â”œâ”€â”€ ğŸ“ src/                    # Core modules
â”‚   â”œâ”€â”€ object_detection_model.py  # ğŸ”§ Main development file
â”‚   â”œâ”€â”€ connection_handler.py      # Server communication
â”‚   â”œâ”€â”€ position_estimator.py      # Camera tracking
â”‚   â”œâ”€â”€ constants.py               # Object classes
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ“ scripts/                # Development tools
â”‚   â”œâ”€â”€ training.ipynb             # Model training
â”‚   â”œâ”€â”€ visualize_yolo.py          # Annotation viewer
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ğŸ“ runs/                   # Training outputs
â”‚   â””â”€â”€ train/weights/best.pt      # Trained model
â”œâ”€â”€ ğŸ“ _images/                # Cached frames
â”œâ”€â”€ ğŸ“ config/                 # Configuration
â”‚   â””â”€â”€ .env                       # Credentials
â””â”€â”€ ğŸ“„ requirements.txt        # Dependencies
```

## ğŸ† Competition Guidelines

### Rules & Constraints

- âœ… **Modifiable**: `object_detection_model.py`, training scripts
- âŒ **Protected**: Server communication, position estimation
- â±ï¸ **Performance**: Must maintain 3 FPS processing
- ğŸ”„ **Real-time**: Frame-by-frame server communication

### Submission Format

The system automatically formats predictions as:
- Bounding boxes with landing status
- Position translations
- JSON payload for server submission

## ğŸ› ï¸ Technical Details

### Dependencies

- **Computer Vision**: OpenCV, Ultralytics YOLO
- **Deep Learning**: PyTorch (via Ultralytics)
- **Communication**: Requests, Python-decouple
- **Processing**: NumPy, Pillow, tqdm

### Performance Optimization

- **Caching**: Local frame storage to avoid re-downloads
- **Resize**: 50% image reduction for faster processing
- **GPU**: CUDA acceleration for YOLO inference

## ğŸ“ˆ Monitoring & Logging

The system generates detailed logs in `_logs/` directory:
- Frame download status
- Detection results
- Server communication
- Error handling

## ğŸ¤ Contributing

This is a competition project with specific modification constraints. For development:

1. Focus changes on `src/object_detection_model.py`
2. Use training scripts for model improvements
3. Test with competition server interface
4. Follow the established data formats

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ… Competition

**Teknofest AI in Transportation Competition**
- Real-time aerial object detection
- Position estimation and tracking
- Landing zone assessment

---

<div align="center">
  <strong>Built for Teknofest 2024 ğŸ‡¹ğŸ‡·</strong>
</div>

